import numpy as np
import warnings
warnings.filterwarnings('ignore')
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, mean_squared_error, mean_absolute_error
from sklearn.model_selection import train_test_split

dataset = pd.read_csv('Weather.csv')
dataset['weather']=dataset['weather'].map({'rain':1,'drizzle':0,'fog':0,'sun':0,'snow':0})
target = ['weather']
features = ['precipitation','temp_max','temp_min','wind']
X = dataset[features]
Y = dataset[target]
#print(dataset["temp_min"].value_counts())
#print(dataset[pd.isnull(dataset["temp_max"])])
'''from  sklearn.impute import SimpleImputer
imputer = SimpleImputer(missing_values=np.nan,strategy='most_frequent')
X = imputer.fit_transform(X)'''



x_train, x_test, y_train, y_test = train_test_split(X, Y,
                                                    train_size=0.7, test_size=0.3, shuffle=False)

'''from sklearn.preprocessing import StandardScaler
sc = StandardScaler()
x_train = sc.fit_transform(x_train)
x_test = sc.fit_transform(x_test)'''
'''print("X_train: {}, x_test: {}".format(len(x_train), len(x_test)))
print("Y_train: {}, y_test: {}".format(len(y_train), len(y_test)))

print("\n")'''

'''model = RandomForestClassifier()

parameters = {'n_estimators' : list(range(10,101,10)),
              'max_features' : list(range(6,32,5))

}





from sklearn.model_selection import GridSearchCV
clf = GridSearchCV(model, parameters, cv=5)
best_clf = clf.fit(X,Y)

bet_cl = best_clf.best_params_     #Returns Parameter names mapped to their values.
print(bet_cl)

#best_clf.fit(x_train,y_train)
#predicted = best_clf.predict(x_test)'''


model = RandomForestClassifier(max_features=6,n_estimators=70)

model.fit(x_train, y_train)
predicted = model.predict(x_test)

def TestrandomF():
              print("Testing Accuracy in Random Forest: {}".format(accuracy_score(y_test, predicted)))
              print("Training Accuracy in Random Forest: {}".format(model.score(x_train, y_train)))

              print('mean_absolute_error Random Forest : ', mean_absolute_error(y_test, predicted))


def GraphR():
    y1=y_test.to_numpy().flatten()  #y_test was a df therefore to numpy flatten method
    y2=predicted.flatten()


    df = pd.DataFrame({'Actual': y1, 'Predicted': y2})
    #print(df)
    df1= df.head(25)
    print("Random forest" + str(df1))
    df1.plot(kind='bar', figsize=(16,10))
    plt.xlabel("Entries")
    plt.ylabel(" Actual vs Prediction")
    plt.title("Graph of Randomforest")
    plt.grid(which='major', linestyle='-',linewidth='0.5', color='green')
    plt.grid(which='minor', linestyle=':',linewidth='0.5', color='black')
    plt.show()


